import streamlit as st
import json
import urllib.request
import urllib.error
import time

# --- Configuration ---
PROJECT_ID = "gen-lang-client-0646195883"
REGION = "us-central1"
# Tuned Endpoint
TUNED_ENDPOINT_ID = "3814882036406026240"
# Base Model ID
BASE_MODEL_ID = "gemini-2.0-flash-001"

# In a real deployed app, use secrets or environment variables!
API_KEY = "AQ.Ab8RN6Kx86NMYSqVQfPivmZ26P7MjS3i6THSEyjKP7fEFmlHfA"

st.set_page_config(page_title="Gemini Model Comparison", page_icon="âš–ï¸", layout="wide")

st.title("âš–ï¸ Gemini Comparison: Base vs Tuned")
st.markdown("ä¸€ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¸¡æ–¹ã®ãƒ¢ãƒ‡ãƒ«ã«é€ä¿¡ã—ã€å›ç­”ã®é•ã„ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")

# --- API Functions ---

def get_base_model_response(prompt):
    url = f"https://{REGION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{REGION}/publishers/google/models/{BASE_MODEL_ID}:streamGenerateContent?key={API_KEY}"
    return call_api(url, prompt)

def get_tuned_model_response(prompt):
    url = f"https://{REGION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{TUNED_ENDPOINT_ID}:streamGenerateContent?key={API_KEY}"
    return call_api(url, prompt)

def call_api(url, prompt):
    payload = {
        "contents": [{"role": "user", "parts": [{"text": prompt}]}],
        "generationConfig": {"maxOutputTokens": 800, "temperature": 0.7}
    }
    
    headers = {"Content-Type": "application/json"}
    data = json.dumps(payload).encode("utf-8")
    
    full_text = ""
    try:
        req = urllib.request.Request(url, data=data, headers=headers, method="POST")
        with urllib.request.urlopen(req) as response:
            while True:
                line = response.readline()
                if not line: break
                try:
                    line_str = line.decode("utf-8")
                    if '"text":' in line_str:
                        import re
                        match = re.search(r'"text":\s*"(.*)"', line_str)
                        if match:
                           chunk = match.group(1).encode('utf-8').decode('unicode_escape')
                           full_text += chunk
                except:
                    pass
    except Exception as e:
        return f"Error: {e}"
    return full_text

# --- UI Layout ---

# Input Area
with st.container():
    prompt = st.text_area("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=100, placeholder="ä¾‹: éƒ¨ä¸‹ã‹ã‚‰æ—¥å ±ãŒæå‡ºã•ã‚Œã¾ã—ãŸãŒå†…å®¹ãŒè–„ã„ã§ã™ã€‚ã©ã†æŒ‡æ‘˜ã—ã¾ã™ã‹ï¼Ÿ")
    submit_btn = st.button("é€ä¿¡ã—ã¦æ¯”è¼ƒã™ã‚‹", type="primary")

if submit_btn and prompt:
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ”¹ Base Model (Untuned)")
        st.caption(f"Model: {BASE_MODEL_ID}")
        with st.spinner("Base Model ç”Ÿæˆä¸­..."):
            base_res = get_base_model_response(prompt)
            st.info(base_res)

    with col2:
        st.subheader("ğŸ”¸ Tuned Model (Fine-Tuned)")
        st.caption(f"Endpoint: {TUNED_ENDPOINT_ID}")
        with st.spinner("Tuned Model ç”Ÿæˆä¸­..."):
            tuned_res = get_tuned_model_response(prompt)
            st.success(tuned_res)

    st.divider()
    st.markdown("### ğŸ’¡ æ¯”è¼ƒã®ãƒã‚¤ãƒ³ãƒˆ")
    st.markdown("- **Base Model**: ä¸€èˆ¬çš„ã€æ•™ç§‘æ›¸çš„ã€æŠ½è±¡åº¦ãŒé«˜ã„å›ç­”ã«ãªã‚ŠãŒã¡ã§ã™ã€‚")
    st.markdown("- **Tuned Model**: ç‹¬è‡ªã®ãƒ«ãƒ¼ãƒ«ã€å½¹å‰²ï¼ˆãƒšãƒ«ã‚½ãƒŠï¼‰ã€å…·ä½“çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã£ãŸå›ç­”ãŒæœŸå¾…ã§ãã¾ã™ã€‚")
